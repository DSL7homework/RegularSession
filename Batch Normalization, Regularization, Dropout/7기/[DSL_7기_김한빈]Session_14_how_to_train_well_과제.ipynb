{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[DSL_7기_김한빈]Session_14_how_to_train_well_과제.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkccGNtCVRc9",
        "outputId": "ae079623-a553-47fd-b04e-e2a9539ba837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Module Importing "
      ],
      "metadata": {
        "id": "qyLUr-jX9_AC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "8gKIdTVHVSqh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Hyperparameter"
      ],
      "metadata": {
        "id": "PNblxDho-KY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 10"
      ],
      "metadata": {
        "id": "liY0seyKVbCp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data "
      ],
      "metadata": {
        "id": "IP-FmCrv-R1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = dset.MNIST(\"./\", train=True, \n",
        "                         transform=transforms.Compose([\n",
        "                             transforms.Resize(34),                             # 원래 28x28인 이미지를 34x34로 늘립니다.\n",
        "                             transforms.CenterCrop(28),                         # 중앙 28x28만을 뽑아냅니다.\n",
        "                             transforms.RandomHorizontalFlip(),                 # 랜덤하게 좌우반전 합니다.\n",
        "                             transforms.Lambda(lambda x: x.rotate(90)),         # 람다함수를 이용해 90도 회전해줍니다.\n",
        "                             transforms.ToTensor(),                             # 이미지를 텐서로 변형합니다.(데이터를 0에서 255까지 있는 값을 0에서 1사이 값으로 변환)\n",
        "                             transforms.Normalize(mean=(0.1307,), std=(0.3081,)) # 정규화입니다. (평균/255=0.1307,표준편차/255=0.3081)\n",
        "                         ]),\n",
        "                         target_transform=None, \n",
        "                         download=True)\n",
        "mnist_test = dset.MNIST(\"./\", train=False, \n",
        "                        transform=transforms.Compose([\n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
        "                        ]),\n",
        "                        target_transform=None, \n",
        "                        download=True)"
      ],
      "metadata": {
        "id": "AiwZ1vIz-N1r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mnist_train.__getitem__(0)[0].size(), mnist_train.__len__())\n",
        "mnist_test.__getitem__(0)[0].size(), mnist_test.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc5wxez3-VE1",
        "outputId": "c7ac437d-4f59-493d-9858-727598945390"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28]) 60000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size, shuffle=False,num_workers=2,drop_last=True)"
      ],
      "metadata": {
        "id": "Vm-WFX0K-YuE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Model  "
      ],
      "metadata": {
        "id": "a4Ek-Rai-fTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(1,16,3,padding=1),  # 1,28,28 \n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.Conv2d(16,32,3,padding=1), # 28 x 28\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.MaxPool2d(2,2),            # 14 x 14\n",
        "            nn.Conv2d(32,64,3,padding=1), # 14 x 14\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.MaxPool2d(2,2)             #  7 x 7\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(64*7*7,100),\n",
        "            nn.BatchNorm1d(100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100,10)\n",
        "        )\n",
        "        #Initialization. \n",
        "      # 초기화 하는 방법\n",
        "        for m in self.modules():\n",
        "          if isinstance(m, nn.Conv2d):\n",
        "            init.kaiming_normal_(m.weight.data)\n",
        "            m.bias.data.fill_(0)\n",
        "          elif isinstance(m, nn.Linear): \n",
        "            init.kaiming_normal_(m.weight.data)\n",
        "            m.bias.data.fill_(0)\n",
        "            \n",
        "    def forward(self,x):\n",
        "        out = self.layer(x)\n",
        "        out = out.view(-1,64*7*7)\n",
        "        out = self.fc_layer(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "IJnv-OwL-dCU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = CNN().to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) #weight_decay=0.01, L2정규화의 lambda=weight_decay\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqMiqcFC-kCM",
        "outputId": "bbbcd473-7653-4f5a-d213-3b603d72cb9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model,(1,28,28), batch_size=256)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj28OZdHjVjo",
        "outputId": "167ee513-4f71-4d0c-e6de-6ab5fbdef9b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [256, 16, 28, 28]             160\n",
            "       BatchNorm2d-2          [256, 16, 28, 28]              32\n",
            "              ReLU-3          [256, 16, 28, 28]               0\n",
            "         Dropout2d-4          [256, 16, 28, 28]               0\n",
            "            Conv2d-5          [256, 32, 28, 28]           4,640\n",
            "       BatchNorm2d-6          [256, 32, 28, 28]              64\n",
            "              ReLU-7          [256, 32, 28, 28]               0\n",
            "         Dropout2d-8          [256, 32, 28, 28]               0\n",
            "         MaxPool2d-9          [256, 32, 14, 14]               0\n",
            "           Conv2d-10          [256, 64, 14, 14]          18,496\n",
            "      BatchNorm2d-11          [256, 64, 14, 14]             128\n",
            "             ReLU-12          [256, 64, 14, 14]               0\n",
            "        Dropout2d-13          [256, 64, 14, 14]               0\n",
            "        MaxPool2d-14            [256, 64, 7, 7]               0\n",
            "           Linear-15                 [256, 100]         313,700\n",
            "      BatchNorm1d-16                 [256, 100]             200\n",
            "             ReLU-17                 [256, 100]               0\n",
            "           Linear-18                  [256, 10]           1,010\n",
            "================================================================\n",
            "Total params: 338,430\n",
            "Trainable params: 338,430\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.77\n",
            "Forward/backward pass size (MB): 410.98\n",
            "Params size (MB): 1.29\n",
            "Estimated Total Size (MB): 413.04\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.Train\n"
      ],
      "metadata": {
        "id": "ara9BUqh_U1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# L1,L2정규화 직접 정의해보기 : 실제 사용할 때는 L2정규화는 optimizer의 weight_decay사용하면 되고, L2 정규화는 train시 for문 안에 넣어줘야 합니다. \n",
        "\n",
        "# all_parameters = torch.cat([x.view(-1) for x in model.parameters()]) \n",
        "# #특정 부분에 제약을 걸고싶으면 \n",
        "# #all_parameters = torch.cat([x.view(-1) for x in model.layer.parameters()])  이렇게 바꿔주시면 됩니다. \n",
        "# lamda1=0.05\n",
        "# l1_regularization = lambda1 * torch.norm(all_parameters, 1)\n",
        "# l2_regularization = lambda1 * torch.norm(all_parameters, 2)\n",
        "\n",
        "# loss = loss_func + l1_regularization \n",
        "# loss = loss_func + l2_regularization "
      ],
      "metadata": {
        "id": "chIPaKf3_R2B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6-1 L1 정규화하여 train "
      ],
      "metadata": {
        "id": "tx0gImek_v-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(num_epoch):\n",
        "    for j,[image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(x)\n",
        "        all_parameters = torch.cat([x.view(-1) for x in model.parameters()])\n",
        "        lambda1=0.05 \n",
        "        l1_regularization = lambda1 * torch.norm(all_parameters, 1)\n",
        "        loss = loss_func(output,y_)+ l1_regularization \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    if i % 10 == 0:\n",
        "      print(loss) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFBneKpB_Yxi",
        "outputId": "35969017-28ef-4b1a-8536-c00c13cdc1bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(381.9536, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7-1.Test"
      ],
      "metadata": {
        "id": "fYdH1kyF_36v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for image,label in test_loader:\n",
        "      x = image.to(device)\n",
        "      y_= label.to(device)\n",
        "\n",
        "      output = model.forward(x)\n",
        "      _,output_index = torch.max(output,1)\n",
        "\n",
        "      total += label.size(0)\n",
        "      correct += (output_index == y_).sum().float()\n",
        "\n",
        "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrw-VDGU_1AB",
        "outputId": "076a1fe2-53ba-4ff8-c579-27baf0282454"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Test Data: 12.960737228393555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-2 Train L2 정규화하여 train "
      ],
      "metadata": {
        "id": "a1sYCCIGBdTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "    for j,[image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(x)\n",
        "        all_parameters = torch.cat([x.view(-1) for x in model.parameters()])\n",
        "        lambda1=0.05 \n",
        "        l2_regularization = lambda1 * torch.norm(all_parameters, 2)\n",
        "        loss = loss_func(output,y_)+ l2_regularization \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(loss) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6nZ6iv8Amey",
        "outputId": "f27864b8-90bd-4882-eec0-d90cf9615be6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8040, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.6171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.6204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.5041, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.4748, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.4456, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.5023, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.4482, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.4266, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "tensor(1.3644, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7-2.Test"
      ],
      "metadata": {
        "id": "aDwnjWL0B34z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for image,label in test_loader:\n",
        "      x = image.to(device)\n",
        "      y_= label.to(device)\n",
        "\n",
        "      output = model.forward(x)\n",
        "      _,output_index = torch.max(output,1)\n",
        "\n",
        "      total += label.size(0)\n",
        "      correct += (output_index == y_).sum().float()\n",
        "\n",
        "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm4bjG3JBtil",
        "outputId": "249b3dd5-43c8-427e-8448-8701fc9f93bd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Test Data: 15.48477554321289\n"
          ]
        }
      ]
    }
  ]
}