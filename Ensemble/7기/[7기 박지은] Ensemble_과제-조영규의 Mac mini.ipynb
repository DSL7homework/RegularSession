{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e9LKkWyU2lZZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SXBhy8mt2lZa"
      },
      "outputs": [],
      "source": [
        "# Prepare dataset\n",
        "data = np.loadtxt('data.csv', delimiter=',', dtype=float)\n",
        "labels = data[:, 0]\n",
        "features = preprocessing.minmax_scale(data[:, 1:])\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels.ravel(), test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0916wFF2lZb"
      },
      "source": [
        "### 의사결정나무\n",
        "* random_state = 2022 으로 설정\n",
        "* 변수명은 dt_clf 로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vDKOMTqa2lZb"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZRa86U7-2lZc"
      },
      "outputs": [],
      "source": [
        "# 빈 부분 코드 작성\n",
        "# decision tree\n",
        "dt_clf = DecisionTreeClassifier(random_state=2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qPoxKVgL2lZc"
      },
      "outputs": [],
      "source": [
        "# 개별 분류기에 train set 피팅\n",
        "dt_clf = dt_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ffA_Bop42lZc"
      },
      "outputs": [],
      "source": [
        "# test셋으로 prediction\n",
        "dt_pred = dt_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da7T3LOs2lZc",
        "outputId": "bf0399cc-1265-49c3-dca9-144d94891086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8613861386138614\n"
          ]
        }
      ],
      "source": [
        "# 성능 확인\n",
        "# accuracy_score 계산\n",
        "print(accuracy_score(dt_pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKBjqrAB2lZd"
      },
      "source": [
        "### 랜덤 포레스트\n",
        "* random_state = 2022\n",
        "* 변수명 rf_clf 로"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "J2W1TuC12lZd"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B2v3PXhi2lZd"
      },
      "outputs": [],
      "source": [
        "# random forest\n",
        "rf_clf = RandomForestClassifier(random_state=2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2yLMIKc82lZe"
      },
      "outputs": [],
      "source": [
        "# 개별 분류기에 train set 피팅\n",
        "rf_clf = rf_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "77ZejC7F2lZe"
      },
      "outputs": [],
      "source": [
        "# test셋으로 prediction\n",
        "rf_pred = rf_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P49f1czn2lZe",
        "outputId": "768fe4d5-7b03-4586-90a2-696ca1ec7483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.900990099009901\n"
          ]
        }
      ],
      "source": [
        "# 성능 확인\n",
        "# accuracy_score 계산\n",
        "print(accuracy_score(rf_pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYyAq0oR2lZe"
      },
      "source": [
        "### Gradient Boost\n",
        "* random_state = 2022\n",
        "* 변수명 gb_clf 로"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2ty-NgAa2lZe"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wBffE8hl2lZe"
      },
      "outputs": [],
      "source": [
        "# gradient boost\n",
        "gb_clf = GradientBoostingClassifier(random_state=2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3tEz_cVl2lZf"
      },
      "outputs": [],
      "source": [
        "# 개별 분류기에 train set 피팅\n",
        "gb_clf = gb_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "24SNWZW_2lZf"
      },
      "outputs": [],
      "source": [
        "# test셋으로 prediction\n",
        "gb_pred = gb_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Evh4dpK2lZf",
        "outputId": "ba644987-47e4-49e3-8489-56c1ee690090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9702970297029703\n"
          ]
        }
      ],
      "source": [
        "# 성능 확인\n",
        "# accuracy_score 계산\n",
        "print(accuracy_score(gb_pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 보고서 과제\n",
        "\n",
        "\n",
        "1. voting, bagging, random forest, boosting, adaboost, gradient boost 의 특징 및 장단점을 스스로 정리해보기\n",
        "    \n",
        "    1) Voting\n",
        "    \n",
        "    - 각 분류기의 예측을 모아서 가장 많이 선택된 클래스를 예측하거나(hard voting), 개별 분류기에서 예측하는 클래스의 확률을 평균 내어 확률이 가ㄴ장 높은 클래스를 예측한다(soft voting).\n",
        "    \n",
        "    2) Bagging\n",
        "    \n",
        "    - 같은 알고리즘을 사용하고 훈련 세트의 서브셋을 무작위로 구성하여 분류기를 각기 다른 훈련 세트로 학습시킨다.\n",
        "    - 단일 model을 활용하여 예측하는 경우와 비교해보았을 때 Bias는 유사하지만 Variance가 감소한다. 또한 중복으로 인해 특정 샘플의 사용 빈도가 높거나 낮아질 수 있다.\n",
        "        \n",
        "        2-1) Random Forest\n",
        "        \n",
        "        - Bagging(또는 Pasting)을 적용한 Decision Tree의 Ensemble\n",
        "    \n",
        "    3) Boosting\n",
        "    \n",
        "    - 앞선 모델을 보완해나가면서 일련의 예측기를 학습시킨다.\n",
        "    - 일반적으로 voting, bagging 보다 성능이 좋지만, 분류기를 순차적으로 학습시키기 때문에 상대적으로 학습 시간이 길며 이상치에 민감하다.\n",
        "        \n",
        "        3-1) AdaBoost\n",
        "        \n",
        "        - 앞선 모델이 과소적합했던 훈련 샘플의 가중치를 높여가며 일련의 예측기를 학습시킨다.\n",
        "        \n",
        "        3-2) Gradient Boost\n",
        "        \n",
        "        - 앞선 모델의 잔여 오차(residual error)에 새로운 예측기를 학습시킨다.\n",
        "<br/><br/>  \n",
        "2. Boosting의 advanced model 인 XGBoost, LightGBM, CatBoost에 대해 찾아보고 정리해보기\n",
        "    \n",
        "    1) XGBoost\n",
        "    \n",
        "    - Boosting을 적용한 Decision Tree의 Ensemble. 병렬 학습을 지원한다는 점에서 Gradient Boost와 구분된다.\n",
        "    \n",
        "    2) LightGBM\n",
        "    \n",
        "    - XGBoost의 학습 속도를 개선한 알고리즘. level-wise가 아닌 leaf-wise 방식으로 트리를 만들어간다는 점에서 다른 Decision Tree 기반 알고리즘들과 구분된다.\n",
        "        - level-wise: 층 단위로 가지치기\n",
        "        - leaf-wise: 잎 단위로 가지치기\n",
        "    \n",
        "    3) CatBoost\n",
        "    \n",
        "    - LightGBM의 Overfitting 문제점을 개선한 알고리즘. 일반적인 Boosting 방삭과는 다르게 Ordered Boosting 방식을 이용함으로써 Overfitting을 예방한다.\n",
        "        - 일반적인 Boosting 방식: 전체적인 오차 값으로 모델을 Ensemble\n",
        "        - Ordered Boosting 방식: 부분의 오차에 대해 모델 생성"
      ],
      "metadata": {
        "id": "UB_sgBPnoatJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFdMg4BC2lZf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Ensemble_과제.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}